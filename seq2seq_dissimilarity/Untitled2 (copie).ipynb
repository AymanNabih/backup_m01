{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import db\n",
    "import pam\n",
    "import utils as ut\n",
    "import features as ft\n",
    "import dtw\n",
    "import clustering_evaluation as ce\n",
    "import seq2seq2 as s2s2\n",
    "import seq2seq as s2s\n",
    "from numpy.linalg import inv\n",
    "import transform_space as ts\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances,homogeneity_completeness_v_measure,silhouette_score,calinski_harabaz_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/grl/\"\n",
    "DATA_BASE = DATA_PATH + \"grl.sqlite\"\n",
    "SAVE_PATH = DATA_PATH + \"generated_data/\"\n",
    "FRAME_PATH = DATA_PATH + \"grl.png\"\n",
    "VIDEO_PATH = DATA_PATH + \"grl.MOV\"\n",
    "HOMOGRAPHY = DATA_PATH + \"homography.txt\"\n",
    "DISTANCES = SAVE_PATH + \"distances/cityblock_50.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_po,ids_po,nb_objects = db.get_trajectories_by_object(DATA_BASE)\n",
    "nb_trajectories_per_object = 1\n",
    "trajectories_po,ids_po = db.filter_trajectories(nb_trajectories_per_object, trajectories_po, ids_po)\n",
    "\n",
    "#total number of selected trajectories\n",
    "nb_trajectories = nb_trajectories_per_object * nb_objects\n",
    "\n",
    "# list of every selected trajectory, \n",
    "trajectories = [t for o in trajectories_po for t in o]\n",
    "# ids of every selected trajectory\n",
    "ids = [i for o in ids_po for i in o]\n",
    "# trajectories in pixel space, for displaying purposes only\n",
    "pixel_trajectories = [ut.to_pixel(t,HOMOGRAPHY) for t in trajectories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2376"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start at 1\n",
    "import math\n",
    "def get_neighboorhood(nb_label,nb_col,hot_cells):\n",
    "    centroids = []\n",
    "    neighboorhoods = []\n",
    "    s = 5\n",
    "    for n in range(1,nb_label+1):\n",
    "        r = int(math.ceil(n/float(nb_col)))\n",
    "        c = nb_col - (r*nb_col - n)\n",
    "        centroid = [(r-1+0.5)*s,(c-1+0.5)*s ]\n",
    "        centroids.append(centroid)\n",
    "        neighboors = [ j*nb_col + i for i in range(c-1,c+2) for j in range(r-1,r+2)  if j*nb_col + i < nb_label+1   and j*nb_col + i != r*nb_col + c and j*nb_col + i != 0 ]\n",
    "        neighboorhoods.append(neighboors)\n",
    "    return neighboorhoods,centroids\n",
    "\n",
    "def get_hot_cells(discretized_trajectory,nb_label,threshold = 15):\n",
    "    a = [i for t in discretized_trajectory for i in t]\n",
    "    b = [0 for i in range(nb_label)]\n",
    "\n",
    "    for e in a:\n",
    "        b[e-1] += 1\n",
    "\n",
    "\n",
    "    hot_cells = [False for i in range(nb_label)]\n",
    "    for i,e in enumerate(b):\n",
    "        if e > threshold:\n",
    "            hot_cells[i] = True \n",
    "    \n",
    "    return hot_cells\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def replace_cold_cells(discretized_trajectory,hot_cells,neighboorhoods):\n",
    "    for trajectory in discretized_trajectory:\n",
    "        for i,p in enumerate(trajectory):\n",
    "            #print(p)\n",
    "            if not hot_cells[p-1]:\n",
    "                #if neighboorhoods[p] != []:\n",
    "                hot_neighbors = [n for n in neighboorhoods[p] if hot_cells[n-1]]\n",
    "                if hot_neighbors != []:\n",
    "                    trajectory[i] = np.random.choice(hot_neighbors)\n",
    "                else:\n",
    "                    trajectory.remove(trajectory[i])\n",
    "                    i -= 1\n",
    "    return discretized_trajectory\n",
    "\n",
    "\n",
    "def discretize_trajectories(trajectories,w,h,s = 5):\n",
    "    w,h = int(round(w)),int(round(h))\n",
    "    \n",
    "    nb_label,nb_row,nb_col = ts.get_nb_label(h,w,s)\n",
    "    discretized_trajectory = [ts.discretize1(t,s,nb_col) for t in trajectories]\n",
    "    \n",
    "    hot_cells = get_hot_cells(discretized_trajectory,nb_label)\n",
    "    #print(hot_cells)\n",
    "    #print(len(hot_cells))\n",
    "    neighboorhoods,centroids = get_neighboorhood(nb_label,nb_col,hot_cells)\n",
    "    discretized_trajectory = replace_cold_cells(discretized_trajectory,hot_cells,neighboorhoods)\n",
    "    # input_size = nb_label +3\n",
    "    nb_label = np.sum([1 for h in hot_cells if h])\n",
    "    \n",
    "    labels = [ i+1 for i,h in enumerate(hot_cells) if h]\n",
    "    \n",
    "    \n",
    "    #print(labels)\n",
    "    #print([np.max(labels)+1,np.max(labels)+2])\n",
    "    \n",
    "    labels = labels + [np.max(labels)+1,np.max(labels)+2]\n",
    "    \n",
    "    dico = {}\n",
    "    for i,l in enumerate(labels):\n",
    "        dico[str(l)] = str(i)\n",
    "    \n",
    "    for i,t in enumerate(discretized_trajectory):\n",
    "        for j,p in enumerate(t):\n",
    "            t[j] = int(dico[str(p)])\n",
    "            \n",
    "    #print(labels)\n",
    "    input_size = nb_label +2\n",
    "    return discretized_trajectory,nb_label,nb_row,nb_col,input_size,labels,dico,centroids,hot_cells\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def one_hot_encode_states_eos1(nb_label,discretized_trajectory):\n",
    "    ohe = OneHotEncoder(sparse = False, dtype=np.int)\n",
    "    #words = np.arange(nb_label+2)\n",
    "    ohe = ohe.fit(np.arange(nb_label+2).reshape(-1,1))\n",
    "\n",
    "    eos = [nb_label+1]\n",
    "    #print(eos)\n",
    "    input_data = [t+eos for t in discretized_trajectory]\n",
    "    #print(input_data)\n",
    "    input_data_encoded = np.array([np.array([ohe.transform(p)[0] for p in t]) for t in input_data])\n",
    "    \n",
    "    sos = np.array([nb_label])\n",
    "    sos_encoded = [ohe.transform(sos[0].reshape(1,-1))[0]]\n",
    "    \n",
    "    return input_data,input_data_encoded,sos,sos_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trajectories_ts,w,h = ts.transform_original_space(trajectories)\n",
    "\n",
    "discretized_trajectory,nb_label,nb_row,nb_col,input_size,labels,dico,centroids,hot_cells  = discretize_trajectories(trajectories_ts,w,h,s = 5)\n",
    "#reversed_discretized_trajectory = [[t[-i] for i in range(1,len(t)+1)] for t in discretized_trajectory ]\n",
    "\n",
    "\n",
    "output_data,_, sos,sos_encoded = one_hot_encode_states_eos1(nb_label,discretized_trajectory)\n",
    "#input_data,input_data_encoded, _,_ = one_hot_encode_states_eos1(nb_label,reversed_discretized_trajectory)\n",
    "input_data,input_data_encoded, _,_ = one_hot_encode_states_eos1(nb_label,discretized_trajectory)\n",
    "\n",
    "\n",
    "#input_data = [[t[-i] for i in range(1,len(t)+1)] for t in output_data_encoded ]\n",
    "# append \n",
    "\n",
    "#features = s2s.unify_trajectory_sizes(encoder,input_data,input_size = input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.214646464646465"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(t) for t in discretized_trajectory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = [c for i,c in enumerate(centroids) if hot_cells[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from math import exp\n",
    "def loss_weight(predicted,real,centroids,theta):\n",
    "    du = euclidean(centroids[predicted],centroids[real])\n",
    "    sdv = np.sum([exp(-euclidean(centroids[real],c)/theta) for c in centroids])\n",
    "    w = exp(-du/theta)/sdv\n",
    "    return w\n",
    "\n",
    "#loss_weight(p,r,centroids,20)\n",
    "# gerer centroid pour sos et eos\n",
    "# a l4infini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids.append([300,300])\n",
    "centroids.append([300,310])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weight_matrix = [[ [] for j in range(input_size)] for i in range(input_size)]\n",
    "for i in range(input_size):\n",
    "    for j in range(i,input_size):\n",
    "        weight_matrix[i][j] = loss_weight(j,i,centroids,10)\n",
    "        weight_matrix[j][i] = weight_matrix[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import utils as ut\n",
    "import features as ft\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size, hidden_size,num_layers=1)\n",
    "\n",
    "    def forward(self, input_, hidden):\n",
    "        #embedded = self.embedding(input).view(1, 1, -1)\n",
    "        #output = embedded\n",
    "        output = input_\n",
    "\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(output_size, hidden_size,num_layers=1)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input_, hidden):\n",
    "        #output = self.embedding(input).view(1, 1, -1)\n",
    "        #output = F.relu(output)\n",
    "        output = input_\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        output = self.out(output)\n",
    "        \n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, h):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor,sos,weight_matrix, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,output_size,teacher_forcing_ratio):\n",
    "    \n",
    "    # initialize hidden state for the encoder\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    # set gradients to zero for both optimizer\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    encoder_outputs,encoder_hidden = encoder.forward(input_tensor,encoder_hidden)\n",
    "    \n",
    "    sos = torch.tensor(sos,dtype = torch.float).view(1,1,input_size)\n",
    "    #EOS = torch.tensor(np.full((24),0),dtype = torch.float).view(1,1,output_size)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    decoder_output,decoder_hidden = decoder.forward(sos,decoder_hidden)\n",
    "    \n",
    "    predicted = np.argmax(np.exp(decoder_output.detach().numpy()))\n",
    "    real = np.max(target_tensor[0].detach().numpy())\n",
    "    \n",
    "    loss += torch.tensor(weight_matrix[real][predicted],dtype = torch.float).view(1) * criterion(decoder_output.view(1,-1), target_tensor[0].view(1) )\n",
    "    \n",
    "    \n",
    "    #print(weight_matrix[real][predicted])\n",
    "    \n",
    "    #while euclidean(EOS,decoder_output) > 1:\n",
    "    for i in range(1,target_tensor.size(0)):\n",
    "        #if random.uniform(0, 1) < teacher_forcing_ratio:\n",
    "          #  decoder_output = target_tensor[i-1].view(1,1,output_size)\n",
    "\n",
    "        decoder_output,decoder_hidden = decoder.forward(decoder_output,decoder_hidden)\n",
    "        \n",
    "        predicted = np.argmax(np.exp(decoder_output.detach().numpy()))\n",
    "        real = np.max(target_tensor[i].detach().numpy())\n",
    "    \n",
    "        loss += torch.tensor(weight_matrix[real][predicted],dtype = torch.float).view(1) *criterion(decoder_output.view(1,-1) , target_tensor[i].view(1) )\n",
    "    \n",
    "    #loss.backward()\n",
    "    \n",
    "    #encoder_optimizer.step()\n",
    "    #decoder_optimizer.step()\n",
    "    \n",
    "    #return loss.item()/target_tensor.size(0)\n",
    "    return loss\n",
    "   \n",
    "def trainIters(encoder, decoder,sos,weight_matrix, X_train,X_test,y_train,y_test, n_epochs,batch_size,input_size,output_size,hidden_size,teacher_forcing_ratio,train_ = 1, print_every=1000, plot_every=100, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    times = []\n",
    "    plot_losses = []\n",
    "    plot_losses_eval = []\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # criterion = nn.MSELoss()\n",
    "    criterion =nn.NLLLoss()\n",
    "    #criterion =nn.CrossEntropyLoss()\n",
    "    best_model = encoder\n",
    "    min_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(1, n_epochs +1 ):\n",
    "        print(\"epoch: \" + str(epoch))\n",
    "        print_loss_total = 0  # Reset every print_every\n",
    "        plot_loss_total = 0  # Reset every plot_every\n",
    "       \n",
    "        loss = 0\n",
    "        for i in range(len(X_train)):\n",
    "            #if i % 400 == 0:\n",
    "                #print(\"proportion training set: \" + str(float(i)/float(len(X_train))))\n",
    "        #x = random.choice(X_train)\n",
    "        #i = np.random.choice(np.arange(len(X_train)),replace = False)\n",
    "            x = X_train[i]\n",
    "            y = y_train[i]\n",
    "\n",
    "           # print(x)\n",
    "            # reverse trajectory order in dataset\n",
    "            #print(x)\n",
    "            input_tensor = torch.tensor(x,dtype=torch.float).view([len(x),batch_size,input_size])\n",
    "            # reverse target order \n",
    "            #x_r = [x[-i] for i in range(2,len(x)+1)] + [x[-1]]\n",
    "\n",
    "            #target_tensor = copy.deepcopy(input_tensor)\n",
    "\n",
    "            target_tensor = torch.tensor(y,dtype=torch.long).view([len(y),batch_size,1])#1\n",
    "\n",
    "            \n",
    "\n",
    "            loss += train(input_tensor, target_tensor,sos,weight_matrix, encoder,decoder, encoder_optimizer, decoder_optimizer, criterion,output_size,teacher_forcing_ratio)\n",
    "            print_loss_total = loss\n",
    "            plot_loss_total = loss\n",
    "\n",
    "            #if epoch % print_every == 0:\n",
    "               # print_loss_avg = print_loss_total / print_every\n",
    "                #print_loss_total = 0\n",
    "                #times.append((time.time()-start,print_loss_avg))\n",
    "            \n",
    "        if train_:\n",
    "           # if epoch % plot_every == 0:\n",
    "                #plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_total.item()/len(X_train))\n",
    "\n",
    "\n",
    "            loss_eval = 0\n",
    "            for t,tt in zip(X_test,y_test):\n",
    "                t = torch.tensor(t,dtype=torch.float).view([len(t),batch_size,input_size])\n",
    "                tt = torch.tensor(tt,dtype=torch.long).view([len(tt),batch_size,1])\n",
    "                loss_eval += evaluate(encoder, decoder,sos,weight_matrix, t,tt ,output_size)\n",
    "            plot_losses_eval.append(loss_eval.item()/len(X_test) )\n",
    "\n",
    "\n",
    "\n",
    "            #print(\"trainloss: \" +str(plot_loss_total))\n",
    "            #print(\"test loss: \" +str(loss_eval))\n",
    "            plot_loss_total = 0\n",
    "            loss_eval = 0\n",
    "        \n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            best_model = encoder    \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "    #print(\"fsfd \")\n",
    "    #print(plot_losses_eval)\n",
    "    if train_:\n",
    "        plt.plot(plot_losses)\n",
    "        plt.plot(plot_losses_eval,color='r')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"best loss is: \"+ str(min_loss))\n",
    "        encoder = best_model\n",
    "    #print(times)\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder,sos,weight_matrix, input_tensor, target_tensor,output_size, threshold = 0.1):\n",
    "#def evaluate(encoder, decoder,criterion, input_tensor, threshold, max_length=MAX_LENGTH ):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_outputs,encoder_hidden = encoder.forward(input_tensor,encoder_hidden)\n",
    "\n",
    "        \n",
    "        sos = torch.tensor(sos,dtype = torch.float).view(1,1,input_size)\n",
    "       # c = nn.MSELoss()\n",
    "        c = nn.NLLLoss()\n",
    "        #criterion =nn.CrossEntropyLoss()\n",
    "        decoder_hidden = encoder_hidden\n",
    "        loss = 0\n",
    "        \n",
    "        outputs = []\n",
    "\n",
    "        decoder_output,decoder_hidden = decoder.forward(sos,decoder_hidden)\n",
    "        \n",
    "        predicted = np.argmax(np.exp(decoder_output.detach().numpy()))\n",
    "        real = np.max(target_tensor[0].detach().numpy())\n",
    "        \n",
    "        loss += torch.tensor(weight_matrix[real][predicted],dtype = torch.float).view(1) *c(decoder_output.view(1,-1), target_tensor[0].view(1) )\n",
    "        \n",
    "        outputs.append(decoder_output)\n",
    "        \n",
    "        for i in range(input_tensor.size(0)):\n",
    "            #dist = euclidean(decoder_output,EOS)\n",
    "            #if dist <= threshold:\n",
    "            #    break\n",
    "            decoder_output,decoder_hidden = decoder.forward(decoder_output,decoder_hidden)\n",
    "            loss += torch.tensor(weight_matrix[real][predicted],dtype = torch.float).view(1) *c(decoder_output.view(1,-1) , target_tensor[i].view(1) )\n",
    "            \n",
    "            predicted = np.argmax(np.exp(decoder_output.detach().numpy()))\n",
    "            real = np.max(target_tensor[i].detach().numpy())\n",
    "            #outputs.append(decoder_output)\n",
    "\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def unify_trajectory_sizes(encoder,X,batch_size = 1,input_size = 24):\n",
    "    D = []\n",
    "    for x in X:        \n",
    "        input_tensor = torch.tensor(x,dtype=torch.float).view([len(x),batch_size,input_size])\n",
    "\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        _,encoder_hidden = encoder.forward(input_tensor,encoder_hidden)\n",
    "        D.append(encoder_hidden.detach().numpy()[0][0])\n",
    "    D = np.array(D)\n",
    "    df = pd.DataFrame(D)\n",
    "    # if normalize == 0:\n",
    "    return df\n",
    "    # std_data = copy.copy(df)\n",
    "    # scaler = StandardScaler()\n",
    "    # std_data[std_data.columns] = scaler.fit_transform(std_data[std_data.columns]) \n",
    "\n",
    "    # return std_data\n",
    "\n",
    "\n",
    "\n",
    "def seq2seq(X,y,sos,weight_matrix,train_ = 1, normalize = 1,batch_size = 1,input_size = 24,output_size = 24,hidden_size = 10,teacher_forcing_ratio = 0,n_epochs = 2000,print_every=1000,plot_every=100,learning_rate=0.001):\n",
    "    encoder = EncoderRNN(input_size,hidden_size)\n",
    "    decoder = DecoderRNN(hidden_size,output_size)\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    if train_:\n",
    "        X_train,X_test , y_train ,y_test = train_test_split(X,y)\n",
    "    else:\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "    start = time.time()\n",
    "    trainIters(\n",
    "        encoder, \n",
    "        decoder, \n",
    "        sos,\n",
    "        weight_matrix,\n",
    "        X_train = X_train,\n",
    "        X_test = X_test, \n",
    "        y_train = y_train,\n",
    "        y_test = y_test,\n",
    "        batch_size = batch_size,\n",
    "        input_size = input_size,\n",
    "        output_size = output_size,\n",
    "        hidden_size = hidden_size,\n",
    "        n_epochs = n_epochs, \n",
    "        print_every=1000, \n",
    "        plot_every=100, \n",
    "        train_ = train_,\n",
    "        teacher_forcing_ratio = teacher_forcing_ratio,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    end = time.time()-start\n",
    "    print(\"duration: \" + str(end))\n",
    "\n",
    "    # D = unify_trajectory_sizes(encoder,X,batch_size,input_size)\n",
    "    # df = pd.DataFrame(D)\n",
    "    # if normalize == 0:\n",
    "    #     return df\n",
    "    # std_data = copy.copy(df)\n",
    "    # scaler = StandardScaler()\n",
    "    # std_data[std_data.columns] = scaler.fit_transform(std_data[std_data.columns]) \n",
    "\n",
    "    # return std_data\n",
    "    return encoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 283.768110991\n"
     ]
    }
   ],
   "source": [
    "#input_size =1\n",
    "encoder = seq2seq(\n",
    "            input_data_encoded,\n",
    "            output_data,\n",
    "            sos_encoded,\n",
    "            weight_matrix,\n",
    "            train_ = 1,\n",
    "            input_size = input_size,\n",
    "            output_size = input_size,\n",
    "            hidden_size = 20,\n",
    "            n_epochs = 20,\n",
    "            learning_rate=0.001\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
